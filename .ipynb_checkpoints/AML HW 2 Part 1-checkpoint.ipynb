{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef761591",
   "metadata": {},
   "source": [
    "# Homework 2 Programming Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c43fda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "20e7cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20a5a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data points: 7613\n",
      "Test data points: 3263\n"
     ]
    }
   ],
   "source": [
    "print('Training data points:', len(train))\n",
    "print('Test data points:', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6c8f8",
   "metadata": {},
   "source": [
    "There are 7613 training data points and 3263 test data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d2fefd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4296597924602653"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train['target'] == 1]) / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb908310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5703402075397347"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train['target'] == 0]) / len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2156b",
   "metadata": {},
   "source": [
    "\\~43% of the training tweets are about real disasters and  \\~57% of the training tweets are not about real disasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5219f13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3b1b2884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>686</td>\n",
       "      <td>attack</td>\n",
       "      <td>#UNITE THE BLUE</td>\n",
       "      <td>@blazerfan not everyone can see ignoranceshe i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>6913</td>\n",
       "      <td>mass%20murderer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White people I know you worry tirelessly about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>6066</td>\n",
       "      <td>heat%20wave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chilli heat wave Doritos never fail!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1441</td>\n",
       "      <td>body%20bagging</td>\n",
       "      <td>New Your</td>\n",
       "      <td>@BroseidonRex @dapurplesharpie I skimmed throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>6365</td>\n",
       "      <td>hostages</td>\n",
       "      <td>cuba</td>\n",
       "      <td>#hot  C-130 specially modified to land in a st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>7025</td>\n",
       "      <td>mayhem</td>\n",
       "      <td>Manavadar, Gujarat</td>\n",
       "      <td>They are the real heroes... RIP Brave hearts.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>4689</td>\n",
       "      <td>engulfed</td>\n",
       "      <td>USA</td>\n",
       "      <td>Car engulfed in flames backs up traffic at Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>2388</td>\n",
       "      <td>collapsed</td>\n",
       "      <td>Alexandria, Egypt.</td>\n",
       "      <td>Great British Bake Off's back and Dorret's cho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>3742</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>USA</td>\n",
       "      <td>Black Eye 9: A space battle occurred at Star O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>3924</td>\n",
       "      <td>devastated</td>\n",
       "      <td>Dorset, UK</td>\n",
       "      <td>???????????? @MikeParrActor absolutely devasta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5329 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          keyword            location  \\\n",
       "476    686           attack   #UNITE THE BLUE     \n",
       "4854  6913  mass%20murderer                 NaN   \n",
       "4270  6066      heat%20wave                 NaN   \n",
       "992   1441   body%20bagging            New Your   \n",
       "4475  6365         hostages                cuba   \n",
       "...    ...              ...                 ...   \n",
       "4931  7025           mayhem  Manavadar, Gujarat   \n",
       "3264  4689         engulfed                 USA   \n",
       "1653  2388        collapsed  Alexandria, Egypt.   \n",
       "2607  3742        destroyed                 USA   \n",
       "2732  3924       devastated          Dorset, UK   \n",
       "\n",
       "                                                   text  \n",
       "476   @blazerfan not everyone can see ignoranceshe i...  \n",
       "4854  White people I know you worry tirelessly about...  \n",
       "4270               Chilli heat wave Doritos never fail!  \n",
       "992   @BroseidonRex @dapurplesharpie I skimmed throu...  \n",
       "4475  #hot  C-130 specially modified to land in a st...  \n",
       "...                                                 ...  \n",
       "4931  They are the real heroes... RIP Brave hearts.....  \n",
       "3264  Car engulfed in flames backs up traffic at Par...  \n",
       "1653  Great British Bake Off's back and Dorret's cho...  \n",
       "2607  Black Eye 9: A space battle occurred at Star O...  \n",
       "2732  ???????????? @MikeParrActor absolutely devasta...  \n",
       "\n",
       "[5329 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X = list(train.columns[:-1])\n",
    "\n",
    "# Splits train.csv into training set (70%) and development set (30%)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(train[X], train['target'], test_size=0.3, random_state=0)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fef4e9f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476     @blazerfan not everyone can see ignoranceshe b...\n",
       "4854    White people I know you worry tirelessly about...\n",
       "4270                 Chilli heat wave Doritos never fail!\n",
       "992     @BroseidonRex @dapurplesharpie I skim through ...\n",
       "4475    #hot C-130 specially modify to land in a stadi...\n",
       "                              ...                        \n",
       "4931    They be the real heroes... RIP Brave hearts......\n",
       "3264    Car engulfed in flame back up traffic at Parle...\n",
       "1653    Great British Bake Off's back and Dorret's cho...\n",
       "2607    Black Eye 9: A space battle occur at Star O784...\n",
       "2732    ???????????? @MikeParrActor absolutely devasta...\n",
       "Name: text, Length: 5329, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet \n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# import nltk\n",
    "# nltk.download()\n",
    "\n",
    "# Lemmatize words based on part of speech (verbs, adjectives, and nouns)\n",
    "def lemmatize(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    word_tags = pos_tag(text.split())\n",
    "    result_text = []\n",
    "    for word_tag in word_tags:\n",
    "        lemmatized_word = word_tag[0]\n",
    "        # lemmatize verbs (e.g. ate -> eat)\n",
    "        if 'VB' in word_tag[1]:\n",
    "            lemmatized_word = wnl.lemmatize(word_tag[0], pos='v')\n",
    "        # lemmatize adjectives (e.g. better -> good)\n",
    "        elif 'JJ' in word_tag[1]:\n",
    "            lemmatized_word = wnl.lemmatize(word_tag[0], pos='a')\n",
    "        # lemmatize nouns (e.g. cookies -> cookie)\n",
    "        elif 'NN' in word_tag[1]:\n",
    "            lemmatized_word = wnl.lemmatize(word_tag[0], pos='n')\n",
    "        result_text.append(lemmatized_word)\n",
    "    return ' '.join(result_text)\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(lambda text: lemmatize(text))\n",
    "X_dev['text'] = X_dev['text'].apply(lambda text: lemmatize(text))\n",
    "X_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "92145aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "stop_words = ['the', 'a', 'an', 'and', 'or', 'this', 'that', 'i', 'my', 'me', 'we', 'us', 'our', 'she', 'her', \n",
    "              'he', 'his', 'him', 'they', 'their', 'them', 'you', 'your', 'there', 'are', 'is', 'from', 'to',\n",
    "              'will', 'can', 'cant', 'would', 'has', 'have', 'could', 'be', 'as', 'if', 'in', 'on', 'also', 'at', \n",
    "              'of', 'into', 'by', 'be', 'it', 'its', 'so', 'im', 'youre', 'theyre', 'hes', 'shes', 'were', 'was', \n",
    "              'not','but', 'no', 'never', 'with', 'really', 'do', 'for', 'about', 'what', 'how', 'who', 'just',\n",
    "              'when', 'via', 'which', 'than']\n",
    "\n",
    "def regex_stop_word(words):\n",
    "    regex = r'\\b'\n",
    "    for i in range(len(words)):\n",
    "        if i == len(words) - 1:\n",
    "            regex += words[i] + r'\\b'\n",
    "        else:\n",
    "            regex += words[i] + r'\\b|\\b'\n",
    "    return regex\n",
    "\n",
    "\n",
    "# Converts all the words to lowercase\n",
    "X_train['text'] = X_train['text'].apply(lambda text: text.lower())\n",
    "X_dev['text'] = X_dev['text'].apply(lambda text: text.lower())\n",
    "\n",
    "# Removes URLs\n",
    "X_train['text'] = X_train['text'].apply(lambda text: re.sub(r'http\\S+', '', text))\n",
    "X_dev['text'] = X_dev['text'].apply(lambda text: re.sub(r'http\\S+', '', text))\n",
    "\n",
    "# Removes user id\n",
    "X_train['text'] = X_train['text'].apply(lambda text: re.sub(r'@(.*?)[\\s]', ' ', text))\n",
    "X_dev['text'] = X_dev['text'].apply(lambda text: re.sub(r'@(.*?)[\\s]', ' ', text))\n",
    "\n",
    "# Strips punctuations\n",
    "X_train['text'] = X_train['text'].apply(lambda text: re.sub(r'[^\\w\\s]', '', text))\n",
    "X_dev['text'] = X_dev['text'].apply(lambda text: re.sub(r'[^\\w\\s]', '', text))\n",
    "\n",
    "# Strips the stop words (the, a, an, and, or)\n",
    "X_train['text'] = X_train['text'].apply(lambda text: re.sub(regex_stop_word(stop_words), '', text))\n",
    "X_dev['text'] = X_dev['text'].apply(lambda text: re.sub(regex_stop_word(stop_words), '', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ce8462e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True, min_df=20)\n",
    "vtz = vectorizer.fit(X_train['text'])\n",
    "V_train = vtz.transform(X_train['text']).toarray()\n",
    "V_dev = vtz.transform(X_dev['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eee88cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.84      3004\n",
      "           1       0.82      0.72      0.76      2325\n",
      "\n",
      "    accuracy                           0.81      5329\n",
      "   macro avg       0.81      0.80      0.80      5329\n",
      "weighted avg       0.81      0.81      0.80      5329\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.80      1338\n",
      "           1       0.74      0.66      0.70       946\n",
      "\n",
      "    accuracy                           0.76      2284\n",
      "   macro avg       0.76      0.75      0.75      2284\n",
      "weighted avg       0.76      0.76      0.76      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# without regularization terms\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = LogisticRegression(penalty='none', max_iter=1000).fit(V_train, y_train)\n",
    "y_train_predict = clf.predict(V_train)\n",
    "results = metrics.classification_report(y_train, y_train_predict)\n",
    "print(results)\n",
    "\n",
    "y_dev_predict = clf.predict(V_dev)\n",
    "results = metrics.classification_report(y_dev, y_dev_predict)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3faa55ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84      3004\n",
      "           1       0.83      0.69      0.75      2325\n",
      "\n",
      "    accuracy                           0.80      5329\n",
      "   macro avg       0.81      0.79      0.79      5329\n",
      "weighted avg       0.81      0.80      0.80      5329\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81      1338\n",
      "           1       0.76      0.64      0.70       946\n",
      "\n",
      "    accuracy                           0.77      2284\n",
      "   macro avg       0.77      0.75      0.76      2284\n",
      "weighted avg       0.77      0.77      0.77      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with L1 regularization\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000).fit(V_train, y_train)\n",
    "y_train_predict = clf_l1.predict(V_train)\n",
    "results = metrics.classification_report(y_train, y_train_predict)\n",
    "print(results)\n",
    "\n",
    "y_dev_predict = clf_l1.predict(V_dev)\n",
    "results = metrics.classification_report(y_dev, y_dev_predict)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "25343cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83      3004\n",
      "           1       0.82      0.70      0.76      2325\n",
      "\n",
      "    accuracy                           0.80      5329\n",
      "   macro avg       0.81      0.79      0.79      5329\n",
      "weighted avg       0.80      0.80      0.80      5329\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81      1338\n",
      "           1       0.75      0.64      0.69       946\n",
      "\n",
      "    accuracy                           0.76      2284\n",
      "   macro avg       0.76      0.75      0.75      2284\n",
      "weighted avg       0.76      0.76      0.76      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with L2 regularization\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_l2 = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000).fit(V_train, y_train)\n",
    "y_train_predict = clf_l2.predict(V_train)\n",
    "results = metrics.classification_report(y_train, y_train_predict)\n",
    "print(results)\n",
    "\n",
    "y_dev_predict = clf_l2.predict(V_dev)\n",
    "results = metrics.classification_report(y_dev, y_dev_predict)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed30bbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mh370', 3.469511379374538),\n",
       " ('release', 3.3738492561960944),\n",
       " ('explode', 3.2527462658073847),\n",
       " ('real', 3.0375415712690406),\n",
       " ('flooding', 3.0086886871873837),\n",
       " ('evacuate', 2.6082943604290314),\n",
       " ('wreck', 2.60156401729194),\n",
       " ('40', 2.354820397417945),\n",
       " ('put', 2.3424630693290567),\n",
       " ('dont', 2.184642617020311),\n",
       " ('survive', 2.15513465807705),\n",
       " ('fire', 2.0603760622823315),\n",
       " ('care', 1.9653333084389681),\n",
       " ('hostage', 1.952064547543393),\n",
       " ('already', 1.7617067278927154),\n",
       " ('death', 1.7314606992997925),\n",
       " ('demolition', 1.7244450431994114),\n",
       " ('full', 1.7109908904321285),\n",
       " ('check', 1.6742057614474313),\n",
       " ('crash', 1.6496428257268485),\n",
       " ('site', 1.6424102887138423),\n",
       " ('collapse', 1.6343846381294267),\n",
       " ('three', 1.6297293439869922),\n",
       " ('city', 1.6175715666882833),\n",
       " ('search', 1.5809614279305781),\n",
       " ('night', 1.5610383490064137),\n",
       " ('content', 1.5332518902736232),\n",
       " ('nuclear', 1.5311303852893194),\n",
       " ('horrible', 1.4903922724023027),\n",
       " ('accident', 1.4883587542047154),\n",
       " ('video', 1.4734914177178478),\n",
       " ('drown', 1.4664990588552878),\n",
       " ('arson', 1.4454996283367234),\n",
       " ('over', 1.4070180457601724),\n",
       " ('today', 1.406446690574447),\n",
       " ('destruction', 1.386266091821974),\n",
       " ('near', 1.3796361248564804),\n",
       " ('ship', 1.334778611637113),\n",
       " ('see', 1.2996098127030262),\n",
       " ('hurricane', 1.2941048223349452),\n",
       " ('natural', 1.277021779037789),\n",
       " ('fatal', 1.25997685513654),\n",
       " ('due', 1.2423789791499236),\n",
       " ('lot', 1.2178383971235343),\n",
       " ('fun', 1.1983273770370944),\n",
       " ('center', 1.1950864252765863),\n",
       " ('massacre', 1.1914619747452977),\n",
       " ('head', 1.1559587338770763),\n",
       " ('tragedy', 1.121149032214898),\n",
       " ('mudslide', 1.1070281874974808),\n",
       " ('back', 1.0992204933537475),\n",
       " ('disaster', 1.0904290399901584),\n",
       " ('obliteration', 1.0833885508091246),\n",
       " ('good', 1.0821419909068353),\n",
       " ('charge', 1.0606505045463381),\n",
       " ('tornado', 1.0569722615412314),\n",
       " ('investigators', 1.0476942183766915),\n",
       " ('debris', 1.0412690867858674),\n",
       " ('lol', 1.0260782056055726),\n",
       " ('bag', 1.0254544423054837),\n",
       " ('70', 0.9982016659583199),\n",
       " ('first', 0.9699623110095489),\n",
       " ('call', 0.9692435924885661),\n",
       " ('dead', 0.9322124971931414),\n",
       " ('must', 0.9209873343766233),\n",
       " ('ban', 0.9198755941710239),\n",
       " ('emergency', 0.9154907180836535),\n",
       " ('car', 0.914669773230655),\n",
       " ('mosque', 0.9132481748715356),\n",
       " ('id', 0.9025391148130479),\n",
       " ('blaze', 0.8993534174260426),\n",
       " ('cake', 0.8863081123441612),\n",
       " ('let', 0.8805923207351021),\n",
       " ('minute', 0.878189617738945),\n",
       " ('more', 0.854088694202802),\n",
       " ('against', 0.8476255658647107),\n",
       " ('something', 0.8294409920379471),\n",
       " ('cyclone', 0.8001396303271471),\n",
       " ('peace', 0.7909005479143182),\n",
       " ('one', 0.7895532886154444),\n",
       " ('why', 0.7894079853109531),\n",
       " ('off', 0.7560240866803046),\n",
       " ('project', 0.740715762026301),\n",
       " ('war', 0.7220231066077788),\n",
       " ('suicide', 0.6985840340916636),\n",
       " ('feel', 0.6921862319332449),\n",
       " ('come', 0.6904782988580541),\n",
       " ('armageddon', 0.661305716803723),\n",
       " ('die', 0.6607260232314051),\n",
       " ('while', 0.6606510042385209),\n",
       " ('fan', 0.6601999552829976),\n",
       " ('right', 0.6346556979471775),\n",
       " ('flame', 0.6298227309285187),\n",
       " ('pick', 0.6113624494653398),\n",
       " ('free', 0.6025320044195767),\n",
       " ('structural', 0.5951705324532279),\n",
       " ('without', 0.5859502668982742),\n",
       " ('life', 0.5815697672110272),\n",
       " ('train', 0.5794034248543116),\n",
       " ('services', 0.5410500420850519),\n",
       " ('hell', 0.5409976624138476),\n",
       " ('try', 0.532866196921964),\n",
       " ('india', 0.5282861272086662),\n",
       " ('suspect', 0.5208531955783329),\n",
       " ('scream', 0.5168906805924137),\n",
       " ('time', 0.5155735923425824),\n",
       " ('12', 0.4665997360726344),\n",
       " ('song', 0.46424933006813174),\n",
       " ('ebay', 0.45942994605727333),\n",
       " ('hiroshima', 0.43656279323076796),\n",
       " ('thing', 0.40408917662087773),\n",
       " ('thanks', 0.39559643584366777),\n",
       " ('home', 0.3721201311582161),\n",
       " ('thank', 0.37007542684386735),\n",
       " ('ruin', 0.3553164576584156),\n",
       " ('hazard', 0.34017050745901145),\n",
       " ('then', 0.3316047787102761),\n",
       " ('game', 0.3304745009498752),\n",
       " ('hot', 0.31775506062233333),\n",
       " ('outbreak', 0.3130224041895188),\n",
       " ('collision', 0.2992705082497979),\n",
       " ('hail', 0.27819181516461877),\n",
       " ('traffic', 0.2780655353306627),\n",
       " ('all', 0.27722523859375614),\n",
       " ('crush', 0.2695914217658618),\n",
       " ('kill', 0.25031883267898186),\n",
       " ('another', 0.2490832334497287),\n",
       " ('hour', 0.2487123040444393),\n",
       " ('attack', 0.24622176465673454),\n",
       " ('yet', 0.2425760010815116),\n",
       " ('set', 0.23556336467194774),\n",
       " ('guy', 0.2265150962834545),\n",
       " ('official', 0.2227939667566214),\n",
       " ('act', 0.21766306985221764),\n",
       " ('spill', 0.21055450718401109),\n",
       " ('day', 0.21055150396355135),\n",
       " ('after', 0.20880781300409665),\n",
       " ('least', 0.20532501641481582),\n",
       " ('these', 0.20313068317875502),\n",
       " ('much', 0.18091546584666546),\n",
       " ('murder', 0.16921530790828046),\n",
       " ('chemical', 0.15562614996686136),\n",
       " ('nearby', 0.13999307938397443),\n",
       " ('rain', 0.1379651018560882),\n",
       " ('bombing', 0.1291053067092873),\n",
       " ('out', 0.12639565804517053),\n",
       " ('panic', 0.12488834978386329),\n",
       " ('migrant', 0.11767860235964372),\n",
       " ('family', 0.09812250594903325),\n",
       " ('sandstorm', 0.09218078790594678),\n",
       " ('ambulance', 0.0880058974743186),\n",
       " ('mass', 0.08610026436251844),\n",
       " ('wound', 0.08271214980856774),\n",
       " ('best', 0.08013576841058301),\n",
       " ('wild', 0.08000730418558732),\n",
       " ('new', 0.07428187889355913),\n",
       " ('report', 0.06915393289792088),\n",
       " ('plane', 0.06646022804783587),\n",
       " ('know', 0.06481767428096309),\n",
       " ('sink', 0.058742595657413056),\n",
       " ('child', 0.04990676359494146),\n",
       " ('stop', 0.04833255125010229),\n",
       " ('body', 0.030747764203150146),\n",
       " ('rt', 0.030424431902747726),\n",
       " ('fedex', 0.022944178415286207),\n",
       " ('trauma', 0.017722048320286506),\n",
       " ('post', 0.017493433319166713),\n",
       " ('state', 0.017374038191141646),\n",
       " ('catastrophe', 0.010451341133694364),\n",
       " ('2015', 0.0030169008545130388),\n",
       " ('affect', 0.0),\n",
       " ('air', 0.0),\n",
       " ('area', 0.0),\n",
       " ('august', 0.0),\n",
       " ('before', 0.0),\n",
       " ('believe', 0.0),\n",
       " ('bioterror', 0.0),\n",
       " ('blight', 0.0),\n",
       " ('block', 0.0),\n",
       " ('bloody', 0.0),\n",
       " ('bomber', 0.0),\n",
       " ('boy', 0.0),\n",
       " ('burn', 0.0),\n",
       " ('catastrophic', 0.0),\n",
       " ('change', 0.0),\n",
       " ('crew', 0.0),\n",
       " ('deal', 0.0),\n",
       " ('demolish', 0.0),\n",
       " ('destroy', 0.0),\n",
       " ('devastation', 0.0),\n",
       " ('down', 0.0),\n",
       " ('evacuation', 0.0),\n",
       " ('everyone', 0.0),\n",
       " ('explosion', 0.0),\n",
       " ('fall', 0.0),\n",
       " ('famine', 0.0),\n",
       " ('flood', 0.0),\n",
       " ('food', 0.0),\n",
       " ('fuck', 0.0),\n",
       " ('get', 0.0),\n",
       " ('group', 0.0),\n",
       " ('harm', 0.0),\n",
       " ('heat', 0.0),\n",
       " ('high', 0.0),\n",
       " ('hijack', 0.0),\n",
       " ('hope', 0.0),\n",
       " ('house', 0.0),\n",
       " ('lab', 0.0),\n",
       " ('landslide', 0.0),\n",
       " ('leave', 0.0),\n",
       " ('level', 0.0),\n",
       " ('little', 0.0),\n",
       " ('long', 0.0),\n",
       " ('look', 0.0),\n",
       " ('make', 0.0),\n",
       " ('man', 0.0),\n",
       " ('may', 0.0),\n",
       " ('military', 0.0),\n",
       " ('national', 0.0),\n",
       " ('need', 0.0),\n",
       " ('northern', 0.0),\n",
       " ('obama', 0.0),\n",
       " ('old', 0.0),\n",
       " ('order', 0.0),\n",
       " ('past', 0.0),\n",
       " ('phone', 0.0),\n",
       " ('pm', 0.0),\n",
       " ('possible', 0.0),\n",
       " ('power', 0.0),\n",
       " ('prebreak', 0.0),\n",
       " ('saw', 0.0),\n",
       " ('sinkhole', 0.0),\n",
       " ('start', 0.0),\n",
       " ('stay', 0.0),\n",
       " ('still', 0.0),\n",
       " ('stock', 0.0),\n",
       " ('story', 0.0),\n",
       " ('thunderstorm', 0.0),\n",
       " ('truck', 0.0),\n",
       " ('turn', 0.0),\n",
       " ('typhoon', 0.0),\n",
       " ('until', 0.0),\n",
       " ('up', 0.0),\n",
       " ('use', 0.0),\n",
       " ('violent', 0.0),\n",
       " ('volcano', 0.0),\n",
       " ('wake', 0.0),\n",
       " ('warning', 0.0),\n",
       " ('watch', 0.0),\n",
       " ('water', 0.0),\n",
       " ('weather', 0.0),\n",
       " ('whirlwind', 0.0),\n",
       " ('whole', 0.0),\n",
       " ('wildfire', 0.0),\n",
       " ('woman', 0.0),\n",
       " ('word', 0.0),\n",
       " ('work', 0.0),\n",
       " ('zone', 0.0),\n",
       " ('Ã»Ã²', 0.0),\n",
       " ('weapon', -0.00023304370011043704),\n",
       " ('airport', -0.004323082875957921),\n",
       " ('miss', -0.0349668493734787),\n",
       " ('ill', -0.04026969937105172),\n",
       " ('fight', -0.041916144877961296),\n",
       " ('love', -0.0533367821176795),\n",
       " ('eye', -0.05933666099270666),\n",
       " ('army', -0.06263461758587772),\n",
       " ('forest', -0.07132409062878119),\n",
       " ('smoke', -0.08400838431689645),\n",
       " ('part', -0.0983360424493502),\n",
       " ('electrocute', -0.1004612493663768),\n",
       " ('terrorist', -0.10552296806744932),\n",
       " ('lava', -0.10632757200530998),\n",
       " ('want', -0.11646173159397069),\n",
       " ('black', -0.128186782197837),\n",
       " ('riot', -0.12856101344039053),\n",
       " ('severe', -0.1319900951914129),\n",
       " ('support', -0.13337442594045434),\n",
       " ('show', -0.13434567748096007),\n",
       " ('during', -0.1348825469043509),\n",
       " ('kid', -0.13940365970497012),\n",
       " ('county', -0.14792339084208794),\n",
       " ('face', -0.1505280278949412),\n",
       " ('blow', -0.15329319162295907),\n",
       " ('confirmed', -0.1538732310619748),\n",
       " ('every', -0.15612873261406499),\n",
       " ('earthquake', -0.17312335581651297),\n",
       " ('boat', -0.17750860759813109),\n",
       " ('think', -0.189251244632787),\n",
       " ('derailment', -0.19330369794637933),\n",
       " ('bridge', -0.19766803944713848),\n",
       " ('storm', -0.203038585216411),\n",
       " ('20', -0.20742743581142237),\n",
       " ('whats', -0.21254444860561433),\n",
       " ('move', -0.21299637956986328),\n",
       " ('murderer', -0.21300986595295335),\n",
       " ('god', -0.21335212427981304),\n",
       " ('update', -0.2388179990017786),\n",
       " ('become', -0.24073928568441377),\n",
       " ('any', -0.262489727073939),\n",
       " ('iran', -0.27481160056858567),\n",
       " ('legionnaires', -0.2790122107269571),\n",
       " ('failure', -0.28096542707471617),\n",
       " ('wind', -0.29607356549109404),\n",
       " ('wont', -0.2988918799572819),\n",
       " ('buildings', -0.3158995252014681),\n",
       " ('obliterate', -0.32369894264147153),\n",
       " ('like', -0.3281566458658891),\n",
       " ('thunder', -0.3341955018376023),\n",
       " ('those', -0.3352480877756477),\n",
       " ('live', -0.3384432253545384),\n",
       " ('people', -0.34543788712645185),\n",
       " ('happen', -0.3548769034488016),\n",
       " ('team', -0.3588341930074894),\n",
       " ('most', -0.35906628173799066),\n",
       " ('photo', -0.36210805801043433),\n",
       " ('both', -0.384668253406701),\n",
       " ('world', -0.38636886522871156),\n",
       " ('great', -0.40712789330464033),\n",
       " ('terrorism', -0.4071939830033964),\n",
       " ('hit', -0.4088582644318149),\n",
       " ('danger', -0.4117352517126119),\n",
       " ('always', -0.44851020287282845),\n",
       " ('news', -0.4493879672541474),\n",
       " ('say', -0.4702934361608865),\n",
       " ('fires', -0.47087804950578227),\n",
       " ('casualty', -0.48560979296431356),\n",
       " ('run', -0.4976440833179892),\n",
       " ('Ã»_', -0.5055221392932037),\n",
       " ('siren', -0.5388074616359437),\n",
       " ('give', -0.5542626038515429),\n",
       " ('girl', -0.5624136849910067),\n",
       " ('bomb', -0.5683863294481071),\n",
       " ('amp', -0.5718564896631206),\n",
       " ('isis', -0.5778769515572468),\n",
       " ('policy', -0.593948777558676),\n",
       " ('play', -0.6053053537396345),\n",
       " ('week', -0.6223912508564051),\n",
       " ('building', -0.6396220692750486),\n",
       " ('bus', -0.6410029921844378),\n",
       " ('lightning', -0.6448381795907073),\n",
       " ('health', -0.6461345078943699),\n",
       " ('sign', -0.663954492065894),\n",
       " ('detonate', -0.6948694724342904),\n",
       " ('should', -0.70633013173087),\n",
       " ('damage', -0.7138106234424013),\n",
       " ('sound', -0.7165053636777045),\n",
       " ('soon', -0.7185415603327562),\n",
       " ('even', -0.7218205419903867),\n",
       " ('other', -0.7356035663634888),\n",
       " ('land', -0.7741859307504297),\n",
       " ('theres', -0.7793996076613141),\n",
       " ('ive', -0.7913960061273535),\n",
       " ('drought', -0.7927592807912536),\n",
       " ('late', -0.8432766715874095),\n",
       " ('burning', -0.851142209356541),\n",
       " ('curfew', -0.8612301689229181),\n",
       " ('plan', -0.9445163898354278),\n",
       " ('two', -0.9674333631809823),\n",
       " ('drive', -0.9750526214832417),\n",
       " ('california', -0.987003291628354),\n",
       " ('now', -1.0362630212796182),\n",
       " ('place', -1.0382309458956922),\n",
       " ('atomic', -1.0416217474118774),\n",
       " ('japan', -1.0861166384890504),\n",
       " ('pandemonium', -1.1633354607636193),\n",
       " ('close', -1.1797010815939861),\n",
       " ('police', -1.1897394333497169),\n",
       " ('trouble', -1.3240945926543575),\n",
       " ('follow', -1.4170255193499346),\n",
       " ('issue', -1.421538920220222),\n",
       " ('top', -1.5537680233117028)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = dict()\n",
    "words = vtz.inverse_transform(clf_l1.coef_)[0]\n",
    "for i in range(len(words)):\n",
    "    param_dict[words[i]] = clf_l1.coef_[0][i]\n",
    "\n",
    "sorted_dict = sorted(param_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2e2a7fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes\n",
    "\n",
    "n = V_train.shape[0]  # number of tweets\n",
    "d = V_train.shape[1]  # number of words in dataset\n",
    "K = 2 # Class size (1 =  real disaster, 0 = not a real disaster)\n",
    "alpha = 1 # Virtual Occurrences\n",
    "\n",
    "psis = np.zeros([K,d])\n",
    "phis = np.zeros([K])\n",
    "\n",
    "for k in range(K):\n",
    "    X_k = V_train[y_train == k]\n",
    "    psis[k] = (np.sum(X_k, axis=0) + alpha) / (X_k.shape[0] + 2 * alpha)\n",
    "    phis[k] = X_k.shape[0] / float(n)\n",
    "\n",
    "    \n",
    "def nb_predictions(x, psis, phis):\n",
    "    \"\"\"This returns class assignments and scores under the NB model.\n",
    "    \n",
    "    We compute \\arg\\max_y p(y|x) as \\arg\\max_y p(x|y)p(y)\n",
    "    \"\"\"\n",
    "    # adjust shapes\n",
    "    n, d = x.shape\n",
    "    x = np.reshape(x, (1, n, d))\n",
    "    psis = np.reshape(psis, (K, 1, d))\n",
    "    \n",
    "    # clip probabilities to avoid log(0)\n",
    "    psis = psis.clip(1e-14, 1-1e-14)\n",
    "    \n",
    "    # compute log-probabilities\n",
    "    logpy = np.log(phis).reshape([K,1])\n",
    "    logpxy = x * np.log(psis) + (1-x) * np.log(1-psis)\n",
    "    logpyx = logpxy.sum(axis=2) + logpy\n",
    "\n",
    "    return logpyx.argmax(axis=0).flatten(), logpyx.reshape([K,n])\n",
    "\n",
    "idx, logpyx = nb_predictions(V_dev, psis, phis)\n",
    "print(idx[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "82f1d624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7596322241681261"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "(idx==y_dev).mean()\n",
    "\n",
    "# Find f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcae5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
